# Adaptive-Early-Exit
# Temporal-aware Early-Exit for Collaborative Inference

This repository implements an **early-exit calibration framework** that combines  
**semantic separability** (Î”S) and a **temporal consistency indicator**,  
inspired by the *COACH: Near Bubble-free Pipeline Collaborative Inference* framework (INFOCOM 2025).

---

## Overview

Recent research such as **COACH (INFOCOMâ€™25)** has shown that collaborative inference pipelines  
can greatly benefit from *temporally stable intermediate features* when determining semantic separability.  
However, in shallow or mid-level layers of DNNs (e.g., ResNet-101 layer3),  
semantic centers tend to be weakly discriminative.  

To address this, we introduce a **temporal consistency auxiliary metric**  
that captures similarity between consecutive frame features,  
stabilizing the Î”S distribution and enabling more reliable early-exit decisions.

---

## Methodology

### 1. Feature Extraction
- **Backbone:** `ResNet-101 (torchvision.models, pretrained on ImageNet1K_V2)`
- **Dataset:** `UCF101` (video action recognition benchmark)
- Extracted **layer1â€“layer4** features using PyTorch forward hooks.
- Applied **temporal mean pooling** (central 5 frames per video):
  ```python
  frames = frames[:, mid-2:mid+3]  # select central 5 frames
  frames = frames.mean(dim=1)      # temporal averaging

### 2. Semantic Center Construction
â€¢	For each class c, compute feature correlations within the same class.
â€¢	Select top-Ï„ (e.g., 70%) highly correlated features.
â€¢	Compute normalized class semantic center:
 semantic_center_c = mean(selected_features) / ||mean(selected_features)||

### 3. Early-Exit Threshold Calibration
	â€¢	Measure semantic separability between top-1 and top-2 similarity scores:
[
Î”S = \frac{S_{top1} - S_{top2}}{|S_{top1}| + |S_{top2}| + \epsilon}
]
	â€¢	Combine with temporal consistency (frame-wise cosine similarity):
[
Hybrid = \alpha \cdot Î”S + \beta \cdot s_{temp}
]
where
â€¢	( s_{temp} = clip(\text{dot}(f_{t-1}, f_t), 0, 1) )
â€¢	typical values: Î± = 0.9, Î² = 0.1
â€¢	Find minimum Ï„ satisfying target edge precision (e.g., 95%):
  if precision(Î”S >= Ï„) >= 0.95:
    best_tau = Ï„
    
### 4. Evaluation (Simulation)
	â€¢	Layer: layer3 (ResNet-101)
	â€¢	Metric: Exit Rate vs Edge Exit Accuracy
	â€¢	Example result:
  Calibrated Ï„_exit = 0.102
  Exit Rate = 20.39%
  Edge Exit Accuracy = 95.36%

ğŸ§  Key Insight

The proposed temporal consistency auxiliary metric enables early-exit
even at semantically ambiguous intermediate layers by stabilizing inter-frame
feature variations, effectively mimicking the â€œtemporal mean featureâ€ strategy of COACH.

This makes early-exit decision-making robust in dynamic scenes,
while maintaining minimal computational overhead (<0.001% of total FLOPs).

â¸»

ğŸ§© Reference

ğŸ”¹ Backbone & Dataset
	â€¢	ResNet-101 â€” He et al., Deep Residual Learning for Image Recognition, CVPR 2016
	â€¢	UCF101 â€” Soomro et al., UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild, CRCV 2012

ğŸ”¹ Base Framework
	â€¢	COACH â€” Zhang et al., COACH: Near Bubble-free Pipeline Collaborative Inference, IEEE INFOCOM 2025
(Referenced for temporal mean pooling and semantic separability calibration)


