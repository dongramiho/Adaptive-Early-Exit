import os
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm

# ============================================================
# Semantic Center Construction (COACH-style)
# - Based on intra-class feature correlation filtering
# - Compatible with small per-class sample sizes (UCF101 subset)
# ============================================================

# -----------------------------
# ê²½ë¡œ ì„¤ì •
# -----------------------------
BASE_DIR = "/home/ubuntu/lab_ws/R3D/mmaction2/tools/data/ucf101/feature_extraction/output"
SAVE_DIR = "/home/ubuntu/lab_ws/R3D/mmaction2/tools/data/ucf101/features"
os.makedirs(SAVE_DIR, exist_ok=True)


def build_semantic_center_for_layer(layer_path, save_path, tau=0.7):
    """
    ê° ë ˆì´ì–´ì— ëŒ€í•´ Semantic Center ê³„ì‚°
    - tau: intra-class correlationì˜ ìƒìœ„ ë¹„ìœ¨ ì„ íƒ (0~1)
    """
    semantic_centers = {}

    for class_name in tqdm(sorted(os.listdir(layer_path)), desc=f"Processing {os.path.basename(layer_path)}"):
        class_dir = os.path.join(layer_path, class_name)
        if not os.path.isdir(class_dir):
            continue

        # í´ë˜ìŠ¤ëª… í†µì¼ (ì†Œë¬¸ì + ì–¸ë”ë°”)
        cls_name = class_name.lower().replace(" ", "_")

        feature_list = []
        for file in os.listdir(class_dir):
            if not file.endswith(".npy"):
                continue

            feat = np.load(os.path.join(class_dir, file))
            feat = np.squeeze(feat)

            # shape í†µì¼ (C,H,W) â†’ í‰ê·  Pool
            if feat.ndim == 3:
                feat = feat.mean(axis=(1, 2))
            elif feat.ndim == 2:
                feat = feat.mean(axis=1)
            elif feat.ndim == 1:
                pass
            else:
                print(f"âš ï¸ Unexpected shape {feat.shape} in {file}, skipping.")
                continue

            # feature ì •ê·œí™” (cosine similarity ì•ˆì •í™”)
            feat = feat / (np.linalg.norm(feat) + 1e-8)
            feature_list.append(feat)

        # ìƒ˜í”Œ ë¶€ì¡±í•œ í´ë˜ìŠ¤ëŠ” skip
        if len(feature_list) < 2:
            continue

        # ìŠ¤íƒ í›„ intra-class correlation ê³„ì‚°
        feats = np.stack(feature_list)
        sim_matrix = cosine_similarity(feats)

        # ê° featureì˜ í‰ê·  correlation ê³„ì‚°
        mean_corr = np.mean(sim_matrix, axis=1)

        # ìƒìœ„ tau quantileì˜ featureë§Œ ì‚¬ìš©
        threshold = np.quantile(mean_corr, tau)
        high_corr_feats = feats[mean_corr >= threshold]

        # Semantic Center ê³„ì‚° (í‰ê·  + ì •ê·œí™”)
        semantic_center = np.mean(high_corr_feats, axis=0)
        semantic_center /= np.linalg.norm(semantic_center) + 1e-8

        semantic_centers[cls_name] = semantic_center

    # npy íŒŒì¼ë¡œ ì €ì¥
    np.save(save_path, semantic_centers)
    print(f"âœ… Saved semantic centers for {os.path.basename(layer_path)} â†’ {save_path}")


# -----------------------------
# ëª¨ë“  ë ˆì´ì–´ ë°˜ë³µ
# -----------------------------
for layer in sorted(os.listdir(BASE_DIR)):
    layer_path = os.path.join(BASE_DIR, layer)
    if not os.path.isdir(layer_path):
        continue

    save_path = os.path.join(SAVE_DIR, f"{layer}_centers.npy")
    build_semantic_center_for_layer(layer_path, save_path, tau=0.7)

print("\nğŸ¯ All layers processed successfully.")